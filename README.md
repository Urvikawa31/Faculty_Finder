# Faculty Finder â€“ AI Research Collaboration Platform

### Public URL: https://infraglyph.vercel.app

---
## Phase 1: Data Engineering Pipeline

## Overview
**Faculty Finder** is an end-to-end **Data Engineering project** that builds a scalable pipeline to discover, extract, store, and serve faculty information from a university website. The system prepares high-quality data for downstream **semantic search and NLP-based applications**.

This repository focuses on **Phase 1: Data Engineering**, covering:
- Data ingestoin
- Data Cleaning & Storage
- API-based data serving

---

## Problem Statement
Faculty expertise information is scattered across unstructured HTML pages and multiple directories. Traditional keyword-based search fails to identify relevant faculty members when exact terms are missing.

Before applying NLP or semantic search, a **robust, reproducible data pipeline** is required to extract and organize this information.

---

## Solution
This project implements a **production-style ETL pipeline** that:

- Crawls multiple faculty directories
- Dynamically discovers faculty profile URLs
- Extracts structured and semi-structured data from profile pages
- Stores **raw HTML content** for future processing
- Exposes data via **FastAPI** for downstream consumption

---

## Architecture

University Website (HTML)<br>
â†“<br>
Faculty URL Discovery<br>
â†“<br>
Profile-Level Scraping<br>
â†“<br>
SQLite Database (Raw HTML Stored)<br>
â†“<br>
Cleaning Raw HTML<br>
â†“<br>
FastAPI (Read-Only APIs)<br>

---

## Pipeline Components

### 1ï¸ Ingestion
- Crawls multiple faculty directories:
  - Regular Faculty
  - Adjunct Faculty
  - International Adjunct Faculty
  - Distinguished Professors
  - Professors of Practice
- Dynamically discovers faculty profile URLs
- Handles real-world issues:
  - Inconsistent URL taxonomy
  - Missing profile fields
  - Absolute and relative URLs
- Uses retry and backoff for robustness

---

### 2ï¸ Extraction
For each faculty profile, the pipeline extracts:
- Name, image, education
- Phone, address, email
- Biography
- Specialization
- Teaching
- Research
- Publications

**Raw HTML is preserved** to support later cleaning and NLP tasks.

---

### 3ï¸ Cleaning & Transformation
- Removes HTML tags and noisy markup
- Normalizes text fields (whitespace, encoding, formatting)
- Handles missing, null, and irregular values gracefully
- Converts semi-structured HTML into clean text suitable for NLP tasks

This step ensures the data is **consistent, readable, and ready for downstream Task**.

---

### 4 Storage
- SQLite database for lightweight persistence
- Schema-driven design
- Raw HTML stored as TEXT fields (Bronze Layer)
- Safe re-runs using unique constraints

---

### 5 Serving (API Layer)
A **FastAPI-based read-only API** provides access to stored data:

| Endpoint | Description |
|--------|------------|
| `GET /faculty` | Fetch all faculty records |
| `GET /faculty/{id}` | Fetch faculty by ID |
| `GET /faculty/category/{category}` | Filter by faculty category |

Swagger UI available at:<br>
local url -> `http://127.0.0.1:8000/docs`<br>
public url -> <br>

---

### Data Analysis & Statistics

#### ğŸ“Š Dataset Overview
- Total Faculty Records: **110**
- Total Attributes per Record: **12 fields**

---

#### Faculty Distribution by Category

| Category | Count | Percentage |
|---------|-------|-----------|
| Regular Faculty | 67 | 60.91% |
| Adjunct Faculty | 26 | 23.64% |
| International Adjunct Faculty | 11 | 10.00% |
| Professor of Practice | 4 | 3.64% |
| Distinguished Professor | 2 | 1.82% |

---

#### Missing Data Analysis

| Field | Missing % |
|-------|----------|
| Education | 1.82% |
| Phone | 29.09% |
| Address | 31.82% |
| Email | 0.91% |
| Biography | 38.18% |
| Specialization | 1.82% |
| Publications | 33.64% |
| Teaching | 36.36% |
| Research | 87.27% |

---

#### Text Length Statistics (NLP Readiness)

| Field | Non-Empty Records | Avg Length | Max Length |
|-------|------------------|----------|----------|
| Biography | 68 | 541 | 2439 |
| Specialization | 108 | 111 | 503 |
| Teaching | 70 | 123 | 1885 |
| Research | 14 | 42 | 1897 |
| Publications | 73 | 1831 | 16202 |

---

## Phase 2: Data Science & AI Layer (Semantic Retrieval + RAG)

### Overview

Building on the structured faculty data prepared in **Phase 1 (Data Engineering)**, this phase extends the system into a **Data Scienceâ€“driven intelligent retrieval engine**.

The goal is to move beyond keyword-based search and enable **research-aware, contextual, and explainable faculty discovery** using a hybrid Retrieval-Augmented Generation (RAG) architecture.

---

### Problem Addressed (Data Science Perspective)

- Faculty profiles contain **rich but noisy unstructured text**
- Keyword matching fails to capture **research intent and semantic similarity**
- Students require **interpretable recommendations**, not just ranked lists
- Traditional search systems lack **contextual understanding**

---

### Solution Approach

The system implements a **hybrid RAG pipeline** that combines classical Information Retrieval with modern embedding-based methods:

- **Keyword relevance** ensures recall
- **Semantic similarity** ensures contextual alignment
- **LLM-based reasoning** ensures interpretability and explainability

---

## AI Architecture (RAG Pipeline)

User Query (HTML)<br>
â†“<br>
Query Cleaning & Embedding<br>
â†“<br>
Hybrid Retrieval<br>
- BM25 (Lexical Matching)<br>
- Sentence Embeddings (Semantic Similarity)<br>
â†“<br>
Score Fusion & Candidate Shortlisting<br>
â†“<br>
LLM-Based Re-Ranking & Explanation<br>
â†“<br>
Final Faculty Recommendations (with reasons)<br>

---

### Core Data Science Components

#### 1ï¸âƒ£ Text Representation

- Cleaned and normalized faculty text fields:
  - Biography  
  - Specialization  
  - Teaching  
  - Research  
  - Publications  
- Sentence-level embeddings using **Sentence Transformers**
- Consistent preprocessing for reliable semantic comparison

---

#### 2ï¸âƒ£ Hybrid Retrieval Strategy

- **BM25** for exact and partial keyword matching
- **Embedding similarity (cosine distance)** for semantic relevance
- Weighted score fusion to balance:
  - Precision  
  - Recall  
  - Research-context alignment

---

#### 3ï¸âƒ£ LLM-Based Explainability Layer

- Large Language Models (LLMs) used for:
  - Re-ranking shortlisted faculty
  - Generating student-friendly explanations
- Explanations cover:
  - Research alignment
  - Potential mentorship value
  - Limitations (adjunct role, sparse data, availability)
- Ensures **transparent and interpretable AI recommendations**

---

#### 4ï¸âƒ£ Robust Output Handling

- Strict **JSON-based structured outputs**
- Safe fallback logic when LLM output is malformed
- Faculty ID preservation to maintain **data lineage and traceability**

---

###  Repository Structure

faculty-finder/<br>
â”‚<br>
â”œâ”€â”€ api/<br>                         
â”‚   â”œâ”€â”€ __pycache__/<br>
â”‚   â”œâ”€â”€ .env<br>
â”‚   â”œâ”€â”€ main.py<br>                  
â”‚   â””â”€â”€ schema.py<br>               
â”‚<br>
â”œâ”€â”€ ingestion/<br>                    
â”‚   â”œâ”€â”€ __pycache__/<br>
â”‚   â”œâ”€â”€ discover_urls.py<br>          
â”‚   â”œâ”€â”€ http_client.py<br>            
â”‚   â””â”€â”€ scrape_faculty.py<br>         
â”‚<br>
â”œâ”€â”€ cleaning/<br>                     
â”‚   â”œâ”€â”€ __pycache__/<br>
â”‚   â”œâ”€â”€ __init__.py<br>
â”‚   â””â”€â”€ clean_faculty_records.py<br>
â”‚<br>
â”œâ”€â”€ storage/<br>                      
â”‚   â”œâ”€â”€ __pycache__/<br>
â”‚   â”œâ”€â”€ db.py<br>                     
â”‚   â”œâ”€â”€ schema.sql<br>                
â”‚   â”œâ”€â”€ init_db.py<br>                
â”‚   â”œâ”€â”€ insert_faculty.py<br>         
â”‚   â”œâ”€â”€ fetch_faculty.py<br>
â”‚   â””â”€â”€ faculty.db<br>                
â”‚<br>
â”œâ”€â”€ pipeline/<br>                     
â”‚   â”œâ”€â”€ step_1_ingestion.py<br>
â”‚   â”œâ”€â”€ step_2_storage.py<br>
â”‚   â””â”€â”€ step_3_cleaning.py<br>
â”‚<br>
â”œâ”€â”€ rag/<br>                          
â”‚   â”œâ”€â”€ __pycache__/<br>
â”‚   â”œâ”€â”€ artifacts/<br>                
â”‚   â”œâ”€â”€ vector_store/<br>             
â”‚   â”œâ”€â”€ step_1_text_construction.py<br>
â”‚   â”œâ”€â”€ step_2_bm25_retrieval.py<br>
â”‚   â”œâ”€â”€ step_3_semantic_index.py<br>
â”‚   â”œâ”€â”€ step_4_semantic_retrieval.py<br>
â”‚   â”œâ”€â”€ step_5_hybrid_retrieval.py<br>
â”‚   â”œâ”€â”€ step_6_llm_explainability.py<br>
â”‚   â””â”€â”€ utils.py<br>
â”‚<br>
â”œâ”€â”€ data/<br>
â”‚   â”œâ”€â”€ raw/<br>                      
â”‚   â”‚   â””â”€â”€ raw_faculty_data.csv<br>
â”‚   â”œâ”€â”€ processed/<br>                
â”‚   â”‚   â””â”€â”€ clean_faculty_data.csv<br>
â”‚<br>
â”œâ”€â”€ data_analysis/<br>                
â”‚   â”œâ”€â”€ __pycache__/<br>
â”‚   â”œâ”€â”€ category_statistics.py<br>
â”‚   â”œâ”€â”€ data_overview.py<br>
â”‚   â”œâ”€â”€ data_quality_checks.py<br>
â”‚   â”œâ”€â”€ load_data.py<br>
â”‚   â”œâ”€â”€ missing_value_statistics.py<br>
â”‚   â”œâ”€â”€ statistics.py<br>
â”‚   â”œâ”€â”€ summary_report.py<br>
â”‚   â””â”€â”€ text_statistics.py<br>
â”‚<br>
â”œâ”€â”€ frontend/<br>                     
â”‚   â”œâ”€â”€ node_modules/<br>
â”‚   â”œâ”€â”€ src/<br>
â”‚   â”‚   â”œâ”€â”€ assets/<br>               
â”‚   â”‚   â”‚   â”œâ”€â”€ infraglyph.png<br>
â”‚   â”‚   â”‚   â””â”€â”€ infraglyph.webp<br>
â”‚   â”‚   â”œâ”€â”€ components/<br>           
â”‚   â”‚   â”‚   â”œâ”€â”€ Header.tsx<br>
â”‚   â”‚   â”‚   â””â”€â”€ Footer.tsx<br>
â”‚   â”‚   â”œâ”€â”€ pages/<br>                
â”‚   â”‚   â”‚   â”œâ”€â”€ Home.tsx<br>
â”‚   â”‚   â”‚   â”œâ”€â”€ SearchResults.tsx<br>
â”‚   â”‚   â”‚   â”œâ”€â”€ FacultyDetail.tsx<br>
â”‚   â”‚   â”‚   â”œâ”€â”€ FacultyList.tsx<br>
â”‚   â”‚   â”‚   â”œâ”€â”€ FeaturedFaculty.tsx<br>
â”‚   â”‚   â”‚   â”œâ”€â”€ DataInsights.tsx<br>
â”‚   â”‚   â”‚   â”œâ”€â”€ HowItWorks.tsx<br>
â”‚   â”‚   â”‚   â””â”€â”€ About.tsx<br>
â”‚   â”‚   â”œâ”€â”€ services/<br>
â”‚   â”‚   â”‚   â””â”€â”€ api.ts<br>             
â”‚   â”‚   â”œâ”€â”€ data/<br>
â”‚   â”‚   â”‚   â””â”€â”€ mockData.ts<br>
â”‚   â”‚   â”œâ”€â”€ App.tsx<br>
â”‚   â”‚   â””â”€â”€ main.tsx<br>
â”‚   â”œâ”€â”€ index.html<br>
â”‚   â”œâ”€â”€ tailwind.config.js<br>
â”‚   â”œâ”€â”€ vite.config.ts<br>
â”‚   â”œâ”€â”€ tsconfig.json<br>
â”‚   â”œâ”€â”€ package.json<br>
â”‚   â””â”€â”€ .env<br>
â”‚<br>
â”œâ”€â”€ logs/<br>
â”‚   â””â”€â”€ llm_usage.md<br>              
â”‚<br>
â”œâ”€â”€ run_pipeline.py<br>               
â”œâ”€â”€ requirements.txt<br>              
â”œâ”€â”€ LICENSE<br>
â””â”€â”€ README.md<br>

##  How to Run

---

## Phase 1: Data Engineering Pipeline

## Entire Pipeline

### 1ï¸ Create Virtual Environment & Install Dependencies
```bash
python -m venv venv
# ubuntu: source venv/bin/activate   # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 2ï¸ Initialize Database
```bash
python storage/init_db.py
```

### 3ï¸ Run Data Pipeline
```bash
python run_pipeline.py
```

### 4ï¸ Start API Server
```bash
uvicorn api.main:app --reload
```

## Step Wise

### 1ï¸ Data Ingestion
```bash
python pipeline/step_1_ingestion.py
```

### 2ï¸ Data Storage
```bash
python pipeline/step_2_storage.py
```

### 3ï¸ Data Cleaning
```bash
python pipeline/step_3_cleaning.py
```
---

## Phase 2: Data Science & AI (RAG Pipeline)

### 1ï¸ Text Construction for Retrieval
```bash
python rag/step_1_text_construction.py
```

### 2ï¸ Lexical Retrieval (BM25)
```bash
python rag/step_2_bm25_retrieval.py
```

### 3ï¸ Semantic Index Construction
```bash
python rag/step_3_semantic_index.py
```

### 4ï¸ Semantic Retrieval
```bash
python rag/step_4_semantic_retrieval.py
```

### 5 Hybrid Retrieval (BM25 + Embeddings)
```bash
python rag/step_5_hybrid_retrieval.py
```

### 6 LLM-Based Explainability
```bash
python rag/step_6_llm_explainability.py
```
---

## Team & Contributions

### Group Name  
**Infraglyph** - Uncovering hidden meaningful patterns

---

### Team Members

| Name | Roll Number |
|------|-------------|
| **Urvi Kava** | 202518006 |
| **Patel Harsh Satishkumar** | 202518011 |

---

### ğŸ”¹ Urvi Kawa (202518006)  
**Role: Data Ingestion, Pipeline Infrastructure, Retrieval Design, RAG Pipeline, System Integration & API Integration**

- Faculty URL discovery and crawling  
- Handling inconsistent website structure and real-world edge cases  
- Profile-level HTML scraping  
- HTTP robustness (retry mechanism and exponential backoff)  
- Database persistence and pipeline orchestration  
- Hybrid retrieval logic (BM25 + embeddings)
- Semantic similarity modeling
- Score fusion and ranking strategies
- End-to-end RAG system design
- AI explainability layer integration
- API integration for AI recommendations

---

### ğŸ”¹ Patel Harsh Satishkumar (202518011)  
**Role: Data Cleaning, Storage, API Layer, RAG Pipeline, System Integration, API Integration, Output Validation & Frontend Alignment**

- Database schema design  
- Cleaning and normalization of scraped data  
- Handling missing and noisy HTML content  
- FastAPI-based read-only API development  
- Documentation and project structuring
- Score fusion and ranking strategies
- End-to-end RAG system design
- AI explainability layer integration
- LLM response handling and validation
- Structured output enforcement
- API integration for AI recommendations
- Frontendâ€“backend data flow alignment
- Performance and reliability improvements

---
